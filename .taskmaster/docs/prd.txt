# Perplexity-Powered Dynamic Questionnaire System PRD
## Product Requirements Document
**Version:** 1.0  
**Date:** October 1, 2025  
**Status:** Ready for Implementation

---

## Executive Summary

Transform the SmartSlate dynamic questionnaire generation from Ollama-only to a Perplexity-first system with Ollama fallback. This enables deep research-backed question generation that adapts to user responses, provides diverse input methods, and ensures zero data loss through robust error handling and comprehensive logging.

---

## Problem Statement

### Current State
- Dynamic questions are generated solely by local Ollama instance
- Limited research capabilities beyond training data cutoff
- No centralized logging for debugging questionnaire issues
- Input types are hardcoded, not dynamically extensible from LLM responses
- No fallback mechanism when Ollama is unavailable

### Desired State
- Perplexity AI (sonar-pro) generates research-backed dynamic questions
- Ollama serves as failsafe fallback
- System accepts and renders ANY input type suggested by LLM
- Comprehensive logging accessible at /logs endpoint
- All data properly saved to database with user_id and blueprint_id association
- Upstream and downstream compatible with existing infrastructure

---

## Goals & Success Metrics

### Primary Goals
1. **Research-Enhanced Questions**: Leverage Perplexity's real-time web research for contextual, industry-specific questions
2. **Zero Downtime**: Automatic fallback to Ollama ensures 100% availability
3. **Extensible Input System**: Support unlimited input types without code changes
4. **Full Observability**: Complete request/response logging for debugging and optimization

### Success Metrics
- 95%+ Perplexity success rate for question generation
- <5s response time for dynamic question generation
- 100% data persistence success rate
- Support for 30+ input types (up from current 27)
- Zero breaking changes to existing wizards

---

## System Architecture

### High-Level Flow
```
User completes static questionnaire
    â†“
API receives static answers + user context
    â†“
Try: Perplexity (sonar-pro) generates dynamic questions with research
    â†“ (if fails)
Fallback: Ollama (local) generates dynamic questions
    â†“
Parse JSON response with sections, questions, input types
    â†“
Validate schema, extend input types if new ones present
    â†“
Save to database (blueprint_generator.dynamic_questions & dynamic_questions_raw)
    â†“
Wizard renders with dynamic input components
    â†“
User completes, saves to dynamic_answers
    â†“
All requests/responses logged for debugging
```

### Component Architecture

#### 1. **API Layer** (`/frontend/app/api/`)
- **`/api/dynamic-questions/route.ts`** (NEW)
  - Receives: `{ blueprintId, staticAnswers, userPrompts }`
  - Orchestrates: Perplexity â†’ Ollama fallback
  - Returns: `{ sections: [], metadata: { model, timestamp, duration } }`
  
- **`/api/perplexity-research/route.ts`** (NEW)
  - Specialized Perplexity endpoint for question generation
  - Timeout: 75s (matches existing Perplexity config)
  - Retries: 2 attempts with exponential backoff

#### 2. **Service Layer** (`/frontend/lib/services/`)
- **`questionGenerationService.ts`** (NEW)
  - `generateWithPerplexity()`: Primary research-backed generation
  - `generateWithOllama()`: Fallback generation
  - `orchestrateGeneration()`: Main coordinator with error handling

#### 3. **Dynamic Form System** (`/frontend/lib/dynamic-form/`)
- **`schema.ts`** (ENHANCED)
  - Add dynamic schema extension mechanism
  - Support unknown input types with graceful degradation
  - Runtime type registration system

- **`components/DynamicInputRegistry.tsx`** (NEW)
  - Render factory for input types
  - Fallback to generic input for unknown types
  - Extensible registration pattern

#### 4. **Database Schema** (EXISTING - No changes needed)
```sql
blueprint_generator:
  - static_answers (JSONB) âœ“
  - dynamic_questions (JSONB) âœ“ Form schema for rendering
  - dynamic_questions_raw (JSONB) âœ“ Raw LLM response
  - dynamic_answers (JSONB) âœ“ User responses
  - user_id (UUID) âœ“
  - id (UUID) âœ“
```

#### 5. **Logging System** (NEW)
- **`/frontend/app/logs/page.tsx`**
  - Real-time log viewer
  - Filter by: level, service, timestamp, user
  - Search and export capabilities

- **`/frontend/lib/logging/`**
  - `logger.ts`: Structured logging service
  - `logStore.ts`: In-memory + persistent storage
  - `types.ts`: Log entry schemas

---

## Detailed Requirements

### FR-1: Perplexity Integration
**Priority:** P0 (Critical)

**Requirements:**
- Use `sonar-pro` model for optimal research depth
- Maximum 8700 tokens per request
- Temperature: 0.1 for consistency
- Include static answers, user prompts in context
- Request web research for industry-specific insights
- Parse strict JSON response

**Prompt Template:**
```
You are an expert Learning Experience Designer with access to current web research.

CONTEXT:
- Static questionnaire responses: {staticAnswers}
- User role: {role}
- Industry: {industry}
- Additional context: {userPrompts}

TASK:
Generate a dynamic questionnaire with 5 sections, 7 questions each (35 total).
Research current best practices for {industry} learning programs.
Adapt questions based on the static responses provided.

OUTPUT SCHEMA (strict JSON):
{
  "sections": [
    {
      "id": "s1",
      "title": "Section Title",
      "description": "Section description",
      "order": 1,
      "questions": [
        {
          "id": "q1_s1",
          "label": "Question text",
          "type": "text|textarea|select|multiselect|radio_pills|radio_cards|checkbox_pills|checkbox_cards|scale|enhanced_scale|labeled_slider|toggle_switch|currency|number_spinner|email|url|date|number",
          "required": true|false,
          "helpText": "Help text",
          "placeholder": "Placeholder",
          "options": [{"value": "v1", "label": "Label 1"}],
          "scaleConfig": {"min": 1, "max": 5, "minLabel": "Low", "maxLabel": "High"},
          "validation": [{"type": "required", "message": "Required"}],
          "metadata": {"researchSource": "citation if applicable"}
        }
      ]
    }
  ],
  "metadata": {
    "generatedAt": "ISO timestamp",
    "model": "sonar-pro",
    "researchCitations": ["source1", "source2"]
  }
}

REQUIREMENTS:
- Use diverse input types based on question nature
- Prefer visual inputs (pills, cards) over traditional select/multiselect
- Use scales for ratings, sliders for ranges
- Include research citations in metadata when applicable
- Ensure logical question flow and dependencies
- NO PREAMBLE OR MARKDOWN - ONLY VALID JSON
```

### FR-2: Ollama Fallback
**Priority:** P0 (Critical)

**Requirements:**
- Activate automatically if Perplexity fails
- Use existing prompt from `.taskmaster/dynamic-questions-prompt.md`
- Same JSON schema as Perplexity
- Log fallback trigger event
- Model: `qwen3:30b-a3b` (current config)
- Timeout: 120s (longer than Perplexity)

**Fallback Triggers:**
- Perplexity API returns 4xx/5xx
- Request timeout (>75s)
- Invalid API key
- Rate limit exceeded
- Network error

### FR-3: Dynamic Input Type System
**Priority:** P0 (Critical)

**Requirements:**
- Parse any `type` value from LLM JSON response
- If type exists in schema (27 current types), render normally
- If type is NEW:
  1. Log new type discovery
  2. Attempt intelligent mapping to closest known type
  3. Render with generic fallback component
  4. Display admin notification for manual implementation
  5. Continue functioning without breaking

**Extensibility Pattern:**
```typescript
// New types auto-register at runtime
const inputTypeRegistry = new Map<string, ComponentType>();

// LLM returns unknown type "date_time_picker"
if (!inputTypeRegistry.has(type)) {
  const mappedType = intelligentTypeMapper(type); // â†’ "date"
  logger.warn('Unknown input type', { type, mappedTo: mappedType });
  return <FallbackInput type={mappedType} {...props} />;
}
```

### FR-4: Data Persistence
**Priority:** P0 (Critical)

**Save Dynamic Questions:**
```sql
UPDATE blueprint_generator
SET 
  dynamic_questions = $1,  -- Form schema for UI
  dynamic_questions_raw = $2,  -- Raw LLM response
  updated_at = now()
WHERE id = $3 AND user_id = $4
```

**Save Dynamic Answers:**
```sql
UPDATE blueprint_generator
SET 
  dynamic_answers = $1,
  status = 'completed',
  updated_at = now()
WHERE id = $2 AND user_id = $3
```

**Validation:**
- Verify blueprint exists and belongs to user
- Validate JSON schema before save
- Handle partial answers (auto-save)
- Optimistic UI updates

### FR-5: Logging System
**Priority:** P1 (High)

**Log Entry Schema:**
```typescript
interface LogEntry {
  id: string;
  timestamp: string;
  level: 'debug' | 'info' | 'warn' | 'error';
  service: string;
  event: string;
  userId?: string;
  blueprintId?: string;
  metadata: {
    duration?: number;
    model?: string;
    error?: string;
    request?: any;
    response?: any;
  };
}
```

**Log Events:**
- `dynamic_questions.perplexity.request`
- `dynamic_questions.perplexity.success`
- `dynamic_questions.perplexity.failure`
- `dynamic_questions.ollama.fallback`
- `dynamic_questions.ollama.success`
- `dynamic_questions.schema.validation`
- `dynamic_questions.input_type.unknown`
- `dynamic_questions.save.success`
- `dynamic_questions.save.failure`

**Logs Page (`/logs`):**
- Real-time updates (SSE or polling)
- Filter by level, service, user, blueprint
- Search functionality
- Export to JSON/CSV
- Secure: Require authentication, admin role check

### FR-6: Wizard Integration
**Priority:** P1 (High)

**Requirements:**
- Maintain existing StepWizard flow
- Add loading state during generation (5-15s expected)
- Display generation source (Perplexity/Ollama badge)
- Show progress indicator
- Allow regeneration if user dissatisfied
- Auto-save answers every 2s
- Resume capability for incomplete questionnaires

---

## Supported Input Types

### Current (27 types)
| Category | Types |
|----------|-------|
| Text | `text`, `textarea`, `email`, `url` |
| Number | `number`, `number_spinner`, `currency` |
| Selection | `select`, `multiselect` |
| Visual Selection | `radio_pills`, `radio_cards`, `checkbox_pills`, `checkbox_cards` |
| Scales | `scale`, `enhanced_scale`, `labeled_slider` |
| Special | `date`, `toggle_switch` |

### Extension Mechanism
- LLM can propose ANY type
- System maps unknown â†’ closest known
- Admin notified for manual implementation
- No breaking changes to existing questionnaires

---

## Technical Specifications

### Environment Variables
```bash
# Perplexity (already configured)
PERPLEXITY_API_KEY=<key>
PERPLEXITY_BASE_URL=https://api.perplexity.ai
PERPLEXITY_MODEL=sonar-pro
PERPLEXITY_MAX_TOKENS=8700
PERPLEXITY_TEMPERATURE=0.1

# Ollama (already configured)
OLLAMA_BASE_URL=http://localhost:11434/api
OLLAMA_MODEL=qwen3:30b-a3b
```

### API Endpoints

**POST `/api/dynamic-questions`**
```typescript
Request: {
  blueprintId: string;
  staticAnswers: Record<string, any>;
  userPrompts?: string[];
}

Response: {
  success: boolean;
  sections: Section[];
  metadata: {
    model: 'perplexity' | 'ollama';
    duration: number;
    timestamp: string;
  };
  error?: string;
}
```

**GET `/api/dynamic-questions/:blueprintId`**
```typescript
Response: {
  questions: Section[];
  answers: Record<string, any>;
  status: 'pending' | 'completed';
}
```

**POST `/api/dynamic-answers`**
```typescript
Request: {
  blueprintId: string;
  answers: Record<string, any>;
}

Response: {
  success: boolean;
  saved: boolean;
}
```

**GET `/api/logs`** (Admin only)
```typescript
Query: {
  level?: string;
  service?: string;
  userId?: string;
  from?: string;
  to?: string;
  limit?: number;
}

Response: {
  logs: LogEntry[];
  total: number;
  page: number;
}
```

---

## Error Handling

### Error Scenarios & Recovery

| Scenario | Recovery Strategy |
|----------|------------------|
| Perplexity timeout | Fallback to Ollama |
| Ollama unavailable | Show cached questions or allow manual input |
| Invalid JSON from LLM | Retry with simplified prompt |
| Unknown input type | Map to closest type, continue |
| Database save failure | Queue for retry, show user notification |
| Network error | Retry with exponential backoff (3 attempts) |

### User-Facing Errors
```typescript
const errorMessages = {
  generation_failed: "We couldn't generate questions right now. Using fallback method.",
  save_failed: "Your answers weren't saved. They're cached locally and will retry automatically.",
  unknown_input: "This question type isn't fully supported yet. Using a simplified version.",
};
```

---

## Testing Requirements

### Unit Tests
- [ ] Perplexity service integration
- [ ] Ollama fallback logic
- [ ] Input type registry and mapping
- [ ] JSON schema validation
- [ ] Logging service

### Integration Tests
- [ ] Full question generation flow (Perplexity â†’ DB)
- [ ] Fallback flow (Perplexity fail â†’ Ollama â†’ DB)
- [ ] Wizard rendering with diverse input types
- [ ] Answer persistence and retrieval
- [ ] Logs API with filtering

### E2E Tests
- [ ] Complete user journey: static â†’ dynamic â†’ answers â†’ blueprint
- [ ] Resume incomplete questionnaire
- [ ] Handle Perplexity outage gracefully
- [ ] New input type discovery and rendering
- [ ] Logs page accessibility and filtering

### Load Tests
- [ ] 10 concurrent question generations
- [ ] Database save performance under load
- [ ] Log system performance (1000+ entries)

---

## Security & Privacy

### Data Protection
- All API routes require authentication (`useSession`)
- RLS policies enforce user_id matching
- Logs scrub sensitive data (API keys, PII)
- Admin-only access to logs page

### API Key Security
- Environment variables only
- Never exposed client-side
- Rotate if compromised
- Rate limiting on endpoints

---

## Migration & Compatibility

### Backward Compatibility
- Existing blueprints with Ollama-generated questions: **No changes needed**
- New blueprints: Use Perplexity by default
- Schema: Fully compatible with existing DB structure
- Wizard: Render old and new questions identically

### Migration Steps
1. Deploy new API endpoints (feature-flagged)
2. Test with subset of users
3. Monitor logs for issues
4. Gradual rollout to 100%
5. Deprecate old generation endpoint after 30 days

---

## Performance Targets

| Metric | Target | Current |
|--------|--------|---------|
| Question generation | <10s | ~15s (Ollama) |
| Fallback activation | <2s | N/A |
| Answer save | <500ms | ~300ms |
| Logs page load | <1s | N/A |
| Wizard render | <2s | ~1.5s |

---

## Rollout Plan

### Phase 1: Foundation (Week 1)
- [ ] Implement logging system
- [ ] Create logs page
- [ ] Add Perplexity service wrapper

### Phase 2: Core Logic (Week 2)
- [ ] Build question generation orchestrator
- [ ] Implement fallback mechanism
- [ ] Add API endpoints

### Phase 3: UI Integration (Week 3)
- [ ] Extend dynamic form system
- [ ] Integrate with wizard
- [ ] Add loading states

### Phase 4: Testing & Polish (Week 4)
- [ ] Complete test suite
- [ ] Performance optimization
- [ ] Documentation

### Phase 5: Launch (Week 5)
- [ ] Feature flag rollout
- [ ] Monitor metrics
- [ ] Collect feedback

---

## Open Questions

1. Should we cache Perplexity responses to save API costs?
2. Do we want user-facing regeneration button in wizard?
3. Should logs be persistent (DB) or ephemeral (in-memory)?
4. Maximum number of dynamic question sets per blueprint?
5. Should we add A/B testing for Perplexity vs Ollama quality?

---

## Success Criteria

### Launch Readiness
- [ ] 100% test coverage for critical paths
- [ ] <1% error rate in staging
- [ ] Logs accessible and useful
- [ ] Documentation complete
- [ ] Security review passed

### Post-Launch (30 days)
- [ ] 90%+ Perplexity success rate
- [ ] <5% fallback activation rate
- [ ] Zero data loss incidents
- [ ] Positive user feedback (NPS >8)
- [ ] Performance targets met

---

## Appendices

### A. Example Perplexity Response
```json
{
  "sections": [
    {
      "id": "s1",
      "title": "Learning Environment Analysis",
      "description": "Understanding your organization's learning ecosystem",
      "order": 1,
      "questions": [
        {
          "id": "q1_s1",
          "label": "What learning management systems (LMS) does your organization currently use?",
          "type": "checkbox_pills",
          "required": true,
          "helpText": "Select all that apply. Based on 2025 industry trends, hybrid LMS adoption is increasing.",
          "options": [
            {"value": "moodle", "label": "Moodle", "icon": "ðŸŽ“"},
            {"value": "canvas", "label": "Canvas", "icon": "ðŸŽ¨"},
            {"value": "blackboard", "label": "Blackboard", "icon": "ðŸ“š"},
            {"value": "cornerstone", "label": "Cornerstone", "icon": "ðŸ¢"},
            {"value": "successfactors", "label": "SAP SuccessFactors", "icon": "ðŸ’¼"},
            {"value": "other", "label": "Other", "icon": "âš™ï¸"}
          ],
          "metadata": {
            "researchSource": "2025 LMS Market Report - MarketsandMarkets"
          }
        }
      ]
    }
  ],
  "metadata": {
    "generatedAt": "2025-10-01T12:34:56Z",
    "model": "sonar-pro",
    "researchCitations": [
      "2025 LMS Market Report - MarketsandMarkets",
      "Learning Tech Trends Q3 2025 - EdTech Review"
    ]
  }
}
```

### B. Input Type Mapping Logic
```typescript
const intelligentTypeMapper = (unknownType: string): InputType => {
  const mappings: Record<string, InputType> = {
    'datetime': 'date',
    'time': 'text',
    'file': 'text',  // Fallback until file upload implemented
    'rich_text': 'textarea',
    'dropdown': 'select',
    'checklist': 'checkbox_pills',
    'rating': 'scale',
  };
  
  return mappings[unknownType.toLowerCase()] || 'text';
};
```

---

**Document End**

